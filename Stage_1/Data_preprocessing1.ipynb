{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from albumentations import Compose, Normalize, Resize, HorizontalFlip, VerticalFlip\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import  HorizontalFlip, VerticalFlip, RandomBrightnessContrast, RandomResizedCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use GPU\n",
    "    print(\"CUDA is available! Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Use CPU\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"SnakeCLEF2021_train_metadata_PROD.csv\")\n",
    "min_train_metadata = pd.read_csv(\"SnakeCLEF2021_min-train_metadata_PROD.csv\")\n",
    "\n",
    "print(len(metadata), len(min_train_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of old paths and corresponding new paths for each folder\n",
    "old_paths = ['/Datasets/SnakeCLEF-2021/inaturalist/', '/Datasets/SnakeCLEF-2021/flickr/', '/Datasets/SnakeCLEF-2021/herpmapper/']\n",
    "new_paths = ['..\\\\Datasets\\\\SnakeCLEF-2021\\\\inaturalist\\\\',\n",
    "             '..\\\\Datasets\\\\SnakeCLEF-2021\\\\flickr\\\\',\n",
    "             '..\\\\Datasets\\\\SnakeCLEF-2021\\\\herpmapper\\\\']\n",
    "\n",
    "# Update the paths in the \"image_path\" column for each folder\n",
    "for old_path, new_path in zip(old_paths, new_paths):\n",
    "    metadata['image_path'] = metadata['image_path'].apply(lambda x: x.replace(old_path, new_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_train_metadata['image_path'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = min_train_metadata\n",
    "val_metadata = metadata[metadata['subset'] == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"..\\\\Datasets\\\\SnakeCLEF-2021\\\\inaturalist\\\\52a171f7b32b49aba243e1f46ab5cf27.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    print(\"Error: Unable to load image\")\n",
    "else:\n",
    "    print(\"Image loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(train_metadata), len(val_metadata))\n",
    "len(min_train_metadata.binomial.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "N_CLASSES = 772\n",
    "BATCH_SIZE = 128\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.df['image_path'].values[idx]\n",
    "        label = self.df['class_id'].values[idx]\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    assert data in ('train', 'valid')\n",
    "\n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            RandomResizedCrop(WIDTH, HEIGHT, scale=(0.8, 1.0)),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            RandomBrightnessContrast(p=0.2),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(WIDTH, HEIGHT),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_stage1 = TrainDataset(train_metadata, transform=get_transforms(data='train'))\n",
    "valid_dataset_stage1 = TrainDataset(val_metadata, transform=get_transforms(data='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for training and validation datasets\n",
    "train_loader = DataLoader(train_dataset_stage1, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "valid_loader = DataLoader(valid_dataset_stage1, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
